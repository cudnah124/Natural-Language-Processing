{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Language Model and Application for Spelling Error Correction\n",
        "\n",
        "Objective: Develop a simple English syntax error correction program.\n",
        "\n",
        "Exercise 1:\n",
        "\n",
        "a) Build a language model based on n-grams using the Laplace smoothing method for the following models:\n",
        "\n",
        "1-gram\n",
        "2-gram\n",
        "3-gram\n",
        "\n",
        "b) Calculate the probability of a sentence and compute the Perplexity of a sentence based on 1-gram, 2-gram, and 3-gram models.\n",
        "\n",
        "c) Analyze the results (Provide your own examples of spelling errors and calculate the probability of two similar sentences, where one has the correct word order and the other has an incorrect word order)."
      ],
      "metadata": {
        "id": "AHcxVwFGQhHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm2X0QDTPBCZ",
        "outputId": "e8ee70f2-eed3-47e3-e9ac-4de823c6343a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.12/dist-packages (0.1.3)\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.12/dist-packages (4.0.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install requests tqdm pandas zipfile36 patool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,glob\n",
        "import codecs\n",
        "import sys\n",
        "import re\n",
        "import requests\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "4dJmxS9CPppt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textword_URL = \"https://raw.githubusercontent.com/cudnah124/Natural-Language-Processing/main/lab3/tedtalk.txt\"\n",
        "textword_PATH = \"tedtalk.txt\"\n",
        "\n",
        "response = requests.get(textword_URL)\n",
        "\n",
        "with open(textword_PATH, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "with open('./tedtalk.txt', 'r', encoding='utf-8') as f:\n",
        "    texttalk = set([line.strip() for line in f])"
      ],
      "metadata": {
        "id": "RI7bDKODP5h7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "sentences = []\n",
        "for line in texttalk:\n",
        "    line = line.lower()\n",
        "    line = re.sub(r'[^a-z\\s]', '', line)\n",
        "    tokens = ['<s>'] + line.split() + ['</s>']\n",
        "    sentences.append(tokens)\n",
        "\n",
        "print(sentences[0])"
      ],
      "metadata": {
        "id": "Ui5HSYITQaOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cf9a87-ace6-449d-d8ec-44c67bf9f36e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', 'i', 'want', 'you', 'now', 'to', 'imagine', 'a', 'wearable', 'robot', 'that', 'gives', 'you', 'superhuman', 'abilities', 'or', 'another', 'one', 'that', 'takes', 'wheelchair', 'users', 'up', 'standing', 'and', 'walking', 'again', 'we', 'at', 'berkeley', 'bionics', 'call', 'these', 'robots', 'exoskeletons', 'these', 'are', 'nothing', 'else', 'than', 'something', 'that', 'you', 'put', 'on', 'in', 'the', 'morning', 'and', 'it', 'will', 'give', 'you', 'extra', 'strength', 'and', 'it', 'will', 'further', 'enhance', 'your', 'speed', 'and', 'it', 'will', 'help', 'you', 'for', 'instance', 'to', 'manage', 'your', 'balance', 'it', 'is', 'actually', 'the', 'true', 'integration', 'of', 'the', 'man', 'and', 'the', 'machine', 'but', 'not', 'only', 'that', 'it', 'will', 'integrate', 'and', 'network', 'you', 'to', 'the', 'universe', 'and', 'other', 'devices', 'out', 'there', 'this', 'is', 'just', 'not', 'some', 'blue', 'sky', 'thinking', 'to', 'show', 'you', 'now', 'what', 'we', 'are', 'working', 'on', 'by', 'starting', 'out', 'talking', 'about', 'the', 'american', 'soldier', 'that', 'on', 'average', 'does', 'carry', 'about', 'lbs', 'on', 'their', 'backs', 'and', 'they', 'are', 'being', 'asked', 'to', 'carry', 'more', 'equipment', 'obviously', 'this', 'is', 'resulting', 'in', 'some', 'major', 'complications', 'back', 'injuries', 'percent', 'of', 'them', 'chronic', 'back', 'injuries', 'so', 'we', 'thought', 'we', 'would', 'look', 'at', 'this', 'challenge', 'and', 'create', 'an', 'exoskeleton', 'that', 'would', 'help', 'deal', 'with', 'this', 'issue', 'so', 'let', 'me', 'now', 'introduce', 'to', 'you', 'hulc', 'or', 'the', 'human', 'universal', 'load', 'carrier', 'soldier', 'with', 'the', 'hulc', 'exoskeleton', 'i', 'can', 'carry', 'lbs', 'over', 'varied', 'terrain', 'for', 'many', 'hours', 'its', 'flexible', 'design', 'allows', 'for', 'deep', 'squats', 'crawls', 'and', 'highagility', 'movements', 'it', 'senses', 'what', 'i', 'want', 'to', 'do', 'where', 'i', 'want', 'to', 'go', 'and', 'then', 'augments', 'my', 'strength', 'and', 'endurance', 'eythor', 'bender', 'we', 'are', 'ready', 'with', 'our', 'industry', 'partner', 'to', 'introduce', 'this', 'device', 'this', 'new', 'exoskeleton', 'this', 'year', 'so', 'this', 'is', 'for', 'real', 'now', 'lets', 'turn', 'our', 'heads', 'towards', 'the', 'wheelchair', 'users', 'something', 'that', 'im', 'particularly', 'passionate', 'about', 'there', 'are', 'million', 'people', 'estimated', 'to', 'be', 'in', 'wheelchairs', 'worldwide', 'this', 'is', 'about', 'one', 'percent', 'of', 'the', 'total', 'population', 'and', 'thats', 'actually', 'a', 'conservative', 'estimate', 'we', 'are', 'talking', 'here', 'about', 'oftentimes', 'very', 'young', 'individuals', 'with', 'spinal', 'cord', 'injuries', 'that', 'in', 'the', 'prime', 'of', 'their', 'life', 's', 's', 's', 'hit', 'a', 'wall', 'and', 'the', 'wheelchairs', 'the', 'only', 'option', 'but', 'it', 'is', 'also', 'the', 'aging', 'population', 'that', 'is', 'multiplying', 'in', 'numbers', 'and', 'the', 'only', 'option', 'pretty', 'much', 'when', 'its', 'stroke', 'or', 'other', 'complications', 'is', 'the', 'wheelchair', 'and', 'that', 'is', 'actually', 'for', 'the', 'last', 'years', 'since', 'its', 'very', 'successful', 'introduction', 'i', 'must', 'say', 'so', 'we', 'thought', 'we', 'would', 'start', 'writing', 'a', 'brand', 'new', 'chapter', 'of', 'mobility', 'let', 'me', 'now', 'introduce', 'you', 'to', 'elegs', 'that', 'is', 'worn', 'by', 'amanda', 'boxtel', 'that', 'years', 'ago', 'was', 'spinal', 'cord', 'injured', 'and', 'as', 'a', 'result', 'of', 'that', 'she', 'has', 'not', 'been', 'able', 'to', 'walk', 'for', 'years', 'until', 'now', 'applause', 'amanda', 'boxtel', 'thank', 'you', 'applause', 'eb', 'amanda', 'is', 'wearing', 'our', 'elegs', 'set', 'it', 'has', 'sensors', 'its', 'completely', 'noninvasive', 'sensors', 'in', 'the', 'crutches', 'that', 'send', 'signals', 'back', 'to', 'our', 'onboard', 'computer', 'that', 'is', 'sitting', 'here', 'at', 'her', 'back', 'there', 'are', 'battery', 'packs', 'here', 'as', 'well', 'that', 'power', 'motors', 'that', 'are', 'sitting', 'at', 'her', 'hips', 'as', 'well', 'as', 'her', 'knee', 'joints', 'that', 'move', 'her', 'forward', 'in', 'this', 'kind', 'of', 'smooth', 'and', 'very', 'natural', 'gait', 'ab', 'i', 'was', 'years', 'old', 'and', 'at', 'the', 'top', 'of', 'my', 'game', 'when', 'a', 'freak', 'summersault', 'while', 'downhill', 'skiing', 'paralyzed', 'me', 'in', 'a', 'split', 'second', 'i', 'lost', 'all', 'sensation', 'and', 'movement', 'below', 'my', 'pelvis', 'not', 'long', 'afterwards', 'a', 'doctor', 'strode', 'into', 'my', 'hospital', 'room', 'and', 'he', 'said', 'amanda', 'youll', 'never', 'walk', 'again', 'and', 'that', 'was', 'yeas', 'ago', 'he', 'robbed', 'every', 'ounce', 'of', 'hope', 'from', 'my', 'being', 'adaptive', 'technology', 'has', 'since', 'enabled', 'me', 'to', 'learn', 'how', 'to', 'downhill', 'ski', 'again', 'to', 'rock', 'climb', 'and', 'even', 'handcycle', 'but', 'nothing', 'has', 'been', 'invented', 'that', 'enables', 'me', 'to', 'walk', 'until', 'now', 'applause', 'thank', 'you', 'applause', 'eb', 'as', 'you', 'can', 'see', 'we', 'have', 'the', 'technology', 'we', 'have', 'the', 'platforms', 'to', 'sit', 'down', 'and', 'have', 'discussions', 'with', 'you', 'its', 'in', 'our', 'hands', 'and', 'we', 'have', 'all', 'the', 'potential', 'here', 'to', 'change', 'the', 'lives', 'of', 'future', 'generations', 'not', 'only', 'for', 'the', 'soldiers', 'or', 'for', 'amanda', 'here', 'and', 'all', 'the', 'wheelchair', 'users', 'but', 'for', 'everyone', 'ab', 'thanks', 'applause', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "\n",
        "for sent in sentences:\n",
        "    unigrams.update(sent)\n",
        "    bigrams.update(zip(sent[:-1], sent[1:]))\n",
        "    trigrams.update(zip(sent[:-2], sent[1:-1], sent[2:]))\n",
        "\n",
        "V = len(unigrams)\n",
        "N = sum(unigrams.values())"
      ],
      "metadata": {
        "id": "1lm4Ii3ybze8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def P_unigram(w):\n",
        "    return (unigrams[w] + 1) / (N + V)\n",
        "def P_bigram(w_prev, w):\n",
        "    return (bigrams[(w_prev, w)] + 1) / (unigrams[w_prev] + V)\n",
        "def P_trigram(w1, w2, w3):\n",
        "    return (trigrams[(w1, w2, w3)] + 1) / (bigrams[(w1, w2)] + V)"
      ],
      "metadata": {
        "id": "SzrHn-eOb5Sb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def sentence_prob_unigram(sent):\n",
        "    prob = 1\n",
        "    for w in sent:\n",
        "        prob *= P_unigram(w)\n",
        "    return prob\n",
        "def sentence_prob_bigram(sent):\n",
        "    prob = 1\n",
        "    for i in range(1, len(sent)):\n",
        "        prob *= P_bigram(sent[i-1], sent[i])\n",
        "    return prob\n",
        "def sentence_prob_trigram(sent):\n",
        "    prob = 1\n",
        "    for i in range(2, len(sent)):\n",
        "        prob *= P_trigram(sent[i-2], sent[i-1], sent[i])\n",
        "    return prob"
      ],
      "metadata": {
        "id": "11SXggMRcB2K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity_unigram(sent):\n",
        "    log_prob = 0\n",
        "    for w in sent:\n",
        "        log_prob += math.log(P_unigram(w))\n",
        "    return math.exp(-log_prob / len(sent))\n",
        "def perplexity_bigram(sent):\n",
        "    log_prob = 0\n",
        "    for i in range(1, len(sent)):\n",
        "        log_prob += math.log(P_bigram(sent[i-1], sent[i]))\n",
        "    return math.exp(-log_prob / (len(sent)-1))\n",
        "def perplexity_trigram(sent):\n",
        "    log_prob = 0\n",
        "    for i in range(2, len(sent)):\n",
        "        log_prob += math.log(P_trigram(sent[i-2], sent[i-1], sent[i]))\n",
        "    return math.exp(-log_prob / (len(sent)-2))"
      ],
      "metadata": {
        "id": "0jzV8o_PcJEn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"P_unigram: \", P_unigram(\"ideas\"))\n",
        "print(f\"P_bigram: \", P_bigram(\"the\", \"world\"))\n",
        "print(f\"P_trigram: \", P_trigram(\"can\", \"change\", \"the\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2_EeTWwcNvG",
        "outputId": "87162af1-8eca-4d95-ccb6-e6fd25512e56"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P_unigram:  0.0002572277456701963\n",
            "P_bigram:  0.020233866975541533\n",
            "P_trigram:  0.0014453928104167964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"<s> ideas can change the world </s>\".split()\n",
        "wrong_order = \"<s> ideas world the change can </s>\".split()\n",
        "spelling_error = \"<s> ideas can chnage the world </s>\".split()\n",
        "\n",
        "tests = {\n",
        "    \"Correct sentence\": test_sentence,\n",
        "    \"Wrong word order\": wrong_order,\n",
        "    \"Spelling error\": spelling_error\n",
        "}\n",
        "\n",
        "for name, sent in tests.items():\n",
        "    print(\"\\n\", name)\n",
        "    print(\"Unigram PP :\", perplexity_unigram(sent))\n",
        "    print(\"Bigram  PP :\", perplexity_bigram(sent))\n",
        "    print(\"Trigram PP:\", perplexity_trigram(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qWTvh7IckDp",
        "outputId": "fe6cbdb6-5417-4916-ba9b-b77da5745d6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Correct sentence\n",
            "Unigram PP : 638.2662319912381\n",
            "Bigram  PP : 1076.2463412324455\n",
            "Trigram PP: 7149.133722973036\n",
            "\n",
            " Wrong word order\n",
            "Unigram PP : 638.2662319912381\n",
            "Bigram  PP : 10596.054946895363\n",
            "Trigram PP: 80025.32849153919\n",
            "\n",
            " Spelling error\n",
            "Unigram PP : 2164.5537383520136\n",
            "Bigram  PP : 8669.044863897736\n",
            "Trigram PP: 52558.14505235626\n"
          ]
        }
      ]
    }
  ]
}